{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "First, packages are imported."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#   import packages\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import functools\n",
    "\n",
    "from ema_workbench import (\n",
    "    Model,\n",
    "    Policy,\n",
    "    Scenario,\n",
    "    ema_logging,\n",
    "    SequentialEvaluator,\n",
    "    MultiprocessingEvaluator,\n",
    "    util,\n",
    "    ScalarOutcome,\n",
    ")\n",
    "from dike_model_function import DikeNetwork  # @UnresolvedImport\n",
    "from problem_formulation import get_model_for_problem_formulation, sum_over, sum_over_time\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "from ema_workbench.em_framework.optimization import ArchiveLogger, EpsilonProgress\n",
    "from ema_workbench.em_framework import parameters_from_csv\n",
    "from ema_workbench.em_framework.optimization import EpsilonProgress\n",
    "from ema_workbench.em_framework.evaluators import BaseEvaluator\n",
    "from ema_workbench.analysis import parcoords"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T18:51:15.015906400Z",
     "start_time": "2023-06-15T18:51:11.777152200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Choice of robustness metrics:\n",
    "\n",
    "\n",
    "| Robustness metric \t |    kind \t     |\n",
    "|:-------------------:|:-------------:|\n",
    "|   Damage Cost          \t   | Minimize    \t |\n",
    "|          \tDeaths Score          |       \tMinimize       |\n",
    "|          \t Dike Invest Cost         |       \tMinimize       |\n",
    "|          RfR Invest Cost       |       \tMinimize       |\n",
    "|          \tEvacuation Cost        |       \tMinimize       |\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, the model is loaded, and logging is set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<Logger EMA (DEBUG)>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dike_model, planning_steps = get_model_for_problem_formulation(5)\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T18:51:15.527817300Z",
     "start_time": "2023-06-15T18:51:15.017894600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The results from the basecase open exploration, which includes the worst scenarios, are loaded into a Pandas DataFrame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "open_exploration_results = pd.read_pickle(r'generated_datasets\\open_exploration_base_policy_worst_scenarios.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T18:51:15.534835400Z",
     "start_time": "2023-06-15T18:51:15.529897700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To calculate the robustness metrics, which are defined as the total annual damage, total expected number of deaths, total dike investment costs, total room for the river costs and total expected evacuation costs, lists of these variables are saved for later use."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# List the names of vars to make `robustness_functions` a bit more read-able\n",
    "var_list_damage = ['A.1_Expected Annual Damage',\n",
    "                   'A.2_Expected Annual Damage',\n",
    "                   'A.3_Expected Annual Damage',\n",
    "                   'A.4_Expected Annual Damage',\n",
    "                   'A.5_Expected Annual Damage',]\n",
    "var_list_deaths = ['A.1_Expected Number of Deaths',\n",
    "                   'A.2_Expected Number of Deaths',\n",
    "                   'A.3_Expected Number of Deaths',\n",
    "                   'A.4_Expected Number of Deaths',\n",
    "                   'A.5_Expected Number of Deaths',]\n",
    "var_list_dike = ['A.1_Dike Investment Costs',\n",
    "                 'A.2_Dike Investment Costs',\n",
    "                 'A.3_Dike Investment Costs',\n",
    "                 'A.4_Dike Investment Costs',\n",
    "                 'A.5_Dike Investment Costs',]\n",
    "var_list_rfr = ['RfR Total Costs',]\n",
    "var_list_evac = ['Expected Evacuation Costs',]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T18:51:15.540004400Z",
     "start_time": "2023-06-15T18:51:15.536879600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, the robustness metric is initiated into a function. For this, we chose LEG UIT.\n",
    "Furthermore, maximalization and minimalization functions are initiated to use in the optimization process."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def robust_sum(*data):\n",
    "    sumsumsum = sum(sum(sum(data)))\n",
    "\n",
    "    # we moeten nog een bron vinden waarom we deze metric gebruiken!\n",
    "    mean = np.mean(sumsumsum)\n",
    "    iqr = sp.stats.iqr(sumsumsum) + mean * 0.005\n",
    "    result = mean + iqr\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T18:51:15.546203Z",
     "start_time": "2023-06-15T18:51:15.542062600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we make the robustness functions and add constraints. We chose minimize and maximize, most conservative (Kwakkel, J. H., Eker, S., & Pruyt, E. (2016). How robust is a robust policy? Comparing alternative robustness metrics for robust decision-making. Robustness analysis in decision aiding, optimization, and analytics, 221-237.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# robustness metrics\n",
    "maximize = ScalarOutcome.MAXIMIZE\n",
    "minimize = ScalarOutcome.MINIMIZE\n",
    "\n",
    "robustness_functions = [\n",
    "    ScalarOutcome('Damage Cost',\n",
    "                  variable_name=var_list_damage,\n",
    "                  function=robust_sum,\n",
    "                  kind=minimize,\n",
    "                  ),\n",
    "    ScalarOutcome('Deaths Score',\n",
    "                  variable_name=var_list_deaths,\n",
    "                  function=robust_sum,\n",
    "                  kind=minimize,\n",
    "                  ),\n",
    "    ScalarOutcome('Dike Invest Cost',\n",
    "                  variable_name=var_list_dike,\n",
    "                  function=robust_sum,\n",
    "                  kind=minimize,\n",
    "                  ),\n",
    "    ScalarOutcome(\"RfR Invest Cost\",\n",
    "                  kind=minimize,\n",
    "                  function=robust_sum,\n",
    "                  variable_name=\"RfR Total Costs\"),\n",
    "    ScalarOutcome(\"Evacuation Cost\",\n",
    "                  kind=minimize,\n",
    "                  function=robust_sum,\n",
    "                  variable_name=\"Expected Evacuation Costs\"),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T18:51:15.553231600Z",
     "start_time": "2023-06-15T18:51:15.548197100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "These scenarios are then loaded into a model variable."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "scenarios = []\n",
    "for row_number in range(open_exploration_results.shape[0]):\n",
    "    scenarios.append(\n",
    "        Scenario(name=row_number, **open_exploration_results.iloc[row_number, :16].to_dict())\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T18:51:15.603344200Z",
     "start_time": "2023-06-15T18:51:15.564749800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convergence metrics are loaded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "convergence_metrics = [\n",
    "    ArchiveLogger(\n",
    "        \"./archives\",\n",
    "        [l.name for l in dike_model.levers],\n",
    "        [o.name for o in robustness_functions],\n",
    "        base_filename=\"robust_optimization_test.tar.gz\",\n",
    "    ),\n",
    "    EpsilonProgress(),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T18:51:15.619344800Z",
     "start_time": "2023-06-15T18:51:15.568918800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, the model variables are set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# general input\n",
    "nfe = int(25) #make this large (2e5)\n",
    "epsilons = [0.05, ]*len(robustness_functions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T18:51:15.619344800Z",
     "start_time": "2023-06-15T18:51:15.573956Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Then, the model can be run. Results are saved."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] pool started with 12 workers\n",
      "  0%|                                                   | 0/25 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Run MORO\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results, convergence = evaluator.robust_optimize(robustness_functions,\n",
    "                                                     scenarios=scenarios,\n",
    "                                                     nfe=nfe,\n",
    "                                                     epsilons=epsilons,\n",
    "                                                     convergence=convergence_metrics,\n",
    "                                                     population_size=5,\n",
    "                                                     )\n",
    "\n",
    "with open(r'generated_datasets/initial_Pareto_policies_test.pkl', 'wb') as file_pi:\n",
    "    pickle.dump(results, file_pi)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-15T18:51:15.585343500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we can continue with the visualization."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(convergence.epsilon_progress)\n",
    "plt.xlabel(\"nr. of generations\")\n",
    "plt.ylabel(r\"$\\epsilon$ progress\")\n",
    "sns.despine()\n",
    "plt.show()\n",
    "sns.set(rc={'figure.figsize':(12,6)})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_pickle(r'generated_datasets/initial_Pareto_policies_test.pkl')\n",
    "\n",
    "data = df.loc[:, [o.name for o in robustness_functions]]\n",
    "limits = parcoords.get_limits(data)\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "paraxes.plot(data)\n",
    "sns.despine()\n",
    "sns.set(rc={'figure.figsize':(12,6)})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scenarios discovery of pareto policies\n",
    "In this analysis, the pareto set of policies is tested on a set of 10.000 scenarios, covering the full uncertainty space."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, the results of the policy discovery is loaded."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pareto_policies = pd.read_pickle(r'generated_datasets/initial_Pareto_policies_test.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, the policies from the analysis are loaded into the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "policies = []\n",
    "for row_number in range(pareto_policies.shape[0]):\n",
    "    policies.append(\n",
    "        Policy(name=row_number, **pareto_policies.iloc[row_number, :-5].to_dict())\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "General settings of the model are set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_scenarios = 50 # maak 10.000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, run the model with the robust policies as input, and generate results over a lot of scenarios"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(scenarios=n_scenarios, policies=policies)\n",
    "\n",
    "with open(r'generated_datasets/policy_test_all_scenarios.pkl', 'wb') as file_pi:\n",
    "    pickle.dump(results, file_pi)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The results are then loaded in for analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scenario_results = pd.read_pickle(r'generated_datasets/policy_test_all_scenarios.pkl')\n",
    "experiments, outcomes = results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make a dataframe column for every timestep of the results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "policies_all_scenarios = pd.DataFrame()\n",
    "for key, value in outcomes.items():\n",
    "    temp_df = pd.DataFrame(value, columns=[key + ' '+ str(x) for x in range(len(value[0]))])\n",
    "    policies_all_scenarios = pd.concat([policies_all_scenarios, temp_df], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add experiments input to the outputs for analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiments_and_results = pd.concat([experiments,policies_all_scenarios], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Combine the variables of different dikes and times"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def combine_columns(dataframe, name):\n",
    "    combined_columns = []\n",
    "    for x in dataframe.columns:\n",
    "        if name in x:\n",
    "            combined_columns.append(x)\n",
    "\n",
    "    dataframe['Total ' + str(name)] = dataframe[combined_columns].sum(axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combine_columns(policies_all_scenarios, 'Expected Annual Damage')\n",
    "combine_columns(policies_all_scenarios, 'Dike Investment Costs')\n",
    "combine_columns(policies_all_scenarios, 'Expected Number of Deaths')\n",
    "combine_columns(policies_all_scenarios, 'RfR Total Costs')\n",
    "combine_columns(policies_all_scenarios, 'Expected Evacuation Costs')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate statistics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aggregated_outcomes = pd.concat([experiments[['scenario','policy']],policies_all_scenarios.iloc[:,-5:]], axis=1)\n",
    "\n",
    "stats_df = pd.DataFrame()\n",
    "for column in aggregated_outcomes.iloc[:,2:].columns:\n",
    "    stats_df[column + ' mean'] = aggregated_outcomes.groupby('policy').agg({column:['mean']})\n",
    "    stats_df[column + ' std'] = aggregated_outcomes.groupby('policy').agg({column:['std']})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A plot with the means and standard deviations of the policies is made, to check reliabilities of the results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn.objects as so\n",
    "(\n",
    "    so.Plot(aggregated_outcomes, y='Total Expected Annual Damage', x=\"policy\")\n",
    "    .add(so.Dot(),so.Agg())\n",
    "    .add(so.Range(),so.Est(errorbar=\"sd\"))\n",
    "    .layout(size=(12, 6))\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Boxplots and barplots are made to compare the results of the policies."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.boxplot(aggregated_outcomes, y='Total Expected Annual Damage', x=\"policy\")\n",
    "sns.set(rc={'figure.figsize':(12,6)})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.boxplot(aggregated_outcomes, y='Total Expected Number of Deaths', x=\"policy\")\n",
    "sns.set(rc={'figure.figsize': (12, 6)})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.boxplot(aggregated_outcomes, y='Total Expected Evacuation Costs', x=\"policy\")\n",
    "sns.set(rc={'figure.figsize': (12, 6)})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.catplot(data=stats_df, x='policy', y='Total Dike Investment Costs mean')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
