{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "In step three, the XLRM specification is used to build a diverse ensemble of possible future states ofthe world (SOWs), or scenarios, that span the uncertainty space specified in the first step. The set offuture SOWs are used to determine how the defined policies may react to a wide variety of possiblefutures. This stage generally involves the use of software to both build the ensemble of scenariosandto apply that ensembleto the set ofpolicy options to build adata set that evaluatesthe potentialeffectiveness of a policy given the XLRM problem definition."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#   import packages\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import functools\n",
    "\n",
    "from ema_workbench import (\n",
    "    Model,\n",
    "    Policy,\n",
    "    Scenario,\n",
    "    ema_logging,\n",
    "    SequentialEvaluator,\n",
    "    MultiprocessingEvaluator,\n",
    "    util,\n",
    "    ScalarOutcome,\n",
    ")\n",
    "from dike_model_function import DikeNetwork  # @UnresolvedImport\n",
    "from problem_formulation import get_model_for_problem_formulation, sum_over, sum_over_time\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "from ema_workbench.em_framework.optimization import ArchiveLogger, EpsilonProgress\n",
    "from ema_workbench.em_framework import parameters_from_csv\n",
    "from ema_workbench.em_framework.evaluators import BaseEvaluator\n",
    "from ema_workbench.analysis import parcoords\n",
    "from ema_workbench.analysis import prim\n",
    "from ema_workbench import Samplers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T14:46:48.654899500Z",
     "start_time": "2023-06-16T14:46:45.856950500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, the model is loaded, and logging is set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<Logger EMA (DEBUG)>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dike_model, planning_steps = get_model_for_problem_formulation(5)\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T14:46:50.927203Z",
     "start_time": "2023-06-16T14:46:49.955779300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, the results of the policy discovery is loaded."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "pareto_policies = pd.read_pickle(r'../generated_datasets/initial_Pareto_policies.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T14:46:58.705089100Z",
     "start_time": "2023-06-16T14:46:58.673350300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, the policies from the analysis are loaded into the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "policies = []\n",
    "for row_number in range(pareto_policies.shape[0]):\n",
    "    policies.append(\n",
    "        Policy(name=row_number, **pareto_policies.iloc[row_number, :-5].to_dict())\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T14:47:00.293798800Z",
     "start_time": "2023-06-16T14:47:00.278112900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "General settings of the model are set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "n_scenarios = int(1e5) # maak 10.000"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T14:47:01.667263500Z",
     "start_time": "2023-06-16T14:47:01.650794500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, run the model with the robust policies as input, and generate results over a lot of scenarios"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] pool started with 12 workers\n",
      "[MainProcess/INFO] performing 50 scenarios * 9 policies * 1 model(s) = 450 experiments\n",
      "100%|████████████████████████████████████████| 450/450 [00:46<00:00,  9.72it/s]\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] terminating pool\n"
     ]
    }
   ],
   "source": [
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(scenarios=n_scenarios,\n",
    "                                            policies=policies,\n",
    "                                            uncertainty_sampling=Samplers.LHS\n",
    "                                            )\n",
    "\n",
    "with open(r'../generated_datasets/policy_uncertainty_test.pkl', 'wb') as file_pi:\n",
    "    pickle.dump(results, file_pi)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T14:48:45.482037Z",
     "start_time": "2023-06-16T14:47:25.746655600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The results are then loaded in for analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "scenario_results = pd.read_pickle(r'../generated_datasets/policy_uncertainty_test.pkl')\n",
    "experiments, outcomes = scenario_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T14:51:33.303187100Z",
     "start_time": "2023-06-16T14:51:33.287457600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make a dataframe column for every timestep of the results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "policies_all_scenarios = pd.DataFrame()\n",
    "for key, value in outcomes.items():\n",
    "    temp_df = pd.DataFrame(value, columns=[key + ' '+ str(x) for x in range(len(value[0]))])\n",
    "    policies_all_scenarios = pd.concat([policies_all_scenarios, temp_df], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T14:51:35.424256700Z",
     "start_time": "2023-06-16T14:51:35.387127Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add experiments input to the outputs for analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "experiments_and_results = pd.concat([experiments,policies_all_scenarios], axis=1)\n",
    "\n",
    "with open(r'../generated_datasets/policy_uncertainty_experiments_results.pkl', 'wb') as file_pi:\n",
    "    pickle.dump(experiments_and_results, file_pi)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T15:44:34.714776700Z",
     "start_time": "2023-06-16T15:44:34.704824600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Combine the variables of different dikes and times"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def combine_columns(dataframe, name):\n",
    "    combined_columns = []\n",
    "    for x in dataframe.columns:\n",
    "        if name in x:\n",
    "            combined_columns.append(x)\n",
    "\n",
    "    dataframe['Total ' + str(name)] = dataframe[combined_columns].sum(axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T14:51:38.211982500Z",
     "start_time": "2023-06-16T14:51:38.193303400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "combine_columns(policies_all_scenarios, 'Expected Annual Damage')\n",
    "combine_columns(policies_all_scenarios, 'Dike Investment Costs')\n",
    "combine_columns(policies_all_scenarios, 'Expected Number of Deaths')\n",
    "combine_columns(policies_all_scenarios, 'RfR Total Costs')\n",
    "combine_columns(policies_all_scenarios, 'Expected Evacuation Costs')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T14:51:40.529170900Z",
     "start_time": "2023-06-16T14:51:40.497253700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate statistics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "aggregated_outcomes = pd.concat([experiments[['scenario','policy']],policies_all_scenarios.iloc[:,-5:]], axis=1)\n",
    "\n",
    "stats_df = pd.DataFrame()\n",
    "for column in aggregated_outcomes.iloc[:,2:].columns:\n",
    "    stats_df[column + ' mean'] = aggregated_outcomes.groupby('policy').agg({column:['mean']})\n",
    "    stats_df[column + ' std'] = aggregated_outcomes.groupby('policy').agg({column:['std']})\n",
    "\n",
    "with open(r'../generated_datasets/policy_uncertainty_aggregated.pkl', 'wb') as file_pi:\n",
    "    pickle.dump(aggregated_outcomes, file_pi)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T15:40:46.549221500Z",
     "start_time": "2023-06-16T15:40:46.487311800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gelderland - Overijssel Split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def combine_columns_province(dataframe, name):\n",
    "    combined_columns_gelderland = []\n",
    "    combined_columns_overijssel = []\n",
    "    for x in dataframe.columns:\n",
    "        if name in x:\n",
    "            if x.startswith('A.1') or x.startswith('A.2') or x.startswith('A.3'):\n",
    "                combined_columns_gelderland.append(x)\n",
    "            if x.startswith('A.4') or x.startswith('A.5'):\n",
    "                combined_columns_overijssel.append(x)\n",
    "\n",
    "    dataframe['Total ' + str(name) + ' Gelderland'] = dataframe[combined_columns_gelderland].sum(axis=1)\n",
    "    dataframe['Total ' + str(name) + ' Overijssel'] = dataframe[combined_columns_overijssel].sum(axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T14:55:37.447714900Z",
     "start_time": "2023-06-16T14:55:37.428415600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "provinces = policies_all_scenarios.copy()\n",
    "\n",
    "combine_columns_province(provinces, 'Expected Annual Damage')\n",
    "combine_columns_province(provinces, 'Dike Investment Costs')\n",
    "combine_columns_province(provinces, 'Expected Number of Deaths')\n",
    "combine_columns_province(provinces, 'RfR Total Costs')\n",
    "combine_columns_province(provinces, 'Expected Evacuation Costs')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T14:55:38.534086200Z",
     "start_time": "2023-06-16T14:55:38.509032400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "aggregated_outcomes_provinces = pd.concat([experiments[['scenario','policy']],provinces.iloc[:,-10:]], axis=1)\n",
    "\n",
    "with open(r'../generated_datasets/policy_uncertainty_provinces.pkl', 'wb') as file_pi:\n",
    "    pickle.dump(aggregated_outcomes_provinces, file_pi)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T15:40:49.165738900Z",
     "start_time": "2023-06-16T15:40:49.149651600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
